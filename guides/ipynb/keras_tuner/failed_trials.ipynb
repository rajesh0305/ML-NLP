{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Handling failed trials in KerasTuner\n",
    "\n",
    "**Authors:** Haifeng Jin<br>\n",
    "**Date created:** 2023/02/28<br>\n",
    "**Last modified:** 2023/02/28<br>\n",
    "**Description:** The basics of fault tolerance configurations in KerasTuner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "A KerasTuner program may take a long time to run since each model may take a\n",
    "long time to train. We do not want the program to fail just because some trials\n",
    "failed randomly.\n",
    "\n",
    "In this guide, we will show how to handle the failed trials in KerasTuner,\n",
    "including:\n",
    "\n",
    "* How to tolerate the failed trials during the search\n",
    "* How to mark a trial as failed during building and evaluating the model\n",
    "* How to terminate the search by raising a `FatalError`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install keras-tuner -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import keras_tuner\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Tolerate failed trials\n",
    "\n",
    "We will use the `max_retries_per_trial` and `max_consecutive_failed_trials`\n",
    "arguments when initializing the tuners.\n",
    "\n",
    "`max_retries_per_trial` controls the maximum number of retries to run if a trial\n",
    "keeps failing. For example, if it is set to 3, the trial may run 4 times (1\n",
    "failed run + 3 failed retries) before it is finally marked as failed. The\n",
    "default value of `max_retries_per_trial` is 0.\n",
    "\n",
    "`max_consecutive_failed_trials` controls how many consecutive failed trials\n",
    "(failed trial here refers to a trial that failed all of its retries) occur\n",
    "before terminating the search. For example, if it is set to 3 and Trial 2, Trial\n",
    "3, and Trial 4 all failed, the search would be terminated. However, if it is set\n",
    "to 3 and only Trial 2, Trial 3, Trial 5, and Trial 6 fail, the search would not\n",
    "be terminated since the failed trials are not consecutive. The default value of\n",
    "`max_consecutive_failed_trials` is 3.\n",
    "\n",
    "The following code shows how these two arguments work in action.\n",
    "\n",
    "* We define a search space with 2 hyperparameters for the number of units in the\n",
    "  2 dense layers.\n",
    "* When their product is larger than 800, we raise a `ValueError` for the model\n",
    "  too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    # Define the 2 hyperparameters for the units in dense layers\n",
    "    units_1 = hp.Int(\"units_1\", 10, 40, step=10)\n",
    "    units_2 = hp.Int(\"units_2\", 10, 30, step=10)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=units_1, input_shape=(20,)),\n",
    "            layers.Dense(units=units_2),\n",
    "            layers.Dense(units=1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"mse\")\n",
    "\n",
    "    # Raise an error when the model is too large\n",
    "    num_params = model.count_params()\n",
    "    if num_params > 1200:\n",
    "        raise ValueError(f\"Model too large! It contains {num_params} params.\")\n",
    "    return model\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We set up the tuner as follows.\n",
    "\n",
    "* We set `max_retries_per_trial=3`.\n",
    "* We set `max_consecutive_failed_trials=8`.\n",
    "* We use `GridSearch` to enumerate all hyperparameter value combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    overwrite=True,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=8,\n",
    ")\n",
    "\n",
    "# Use random data to train the model.\n",
    "tuner.search(\n",
    "    x=np.random.rand(100, 20),\n",
    "    y=np.random.rand(100, 1),\n",
    "    validation_data=(\n",
    "        np.random.rand(100, 20),\n",
    "        np.random.rand(100, 1),\n",
    "    ),\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Print the results.\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Mark a trial as failed\n",
    "\n",
    "When the model is too large, we do not need to retry it. No matter how many\n",
    "times we try with the same hyperparameters, it is always too large.\n",
    "\n",
    "We can set `max_retries_per_trial=0` to do it. However, it will not retry no\n",
    "matter what errors are raised while we may still want to retry for other\n",
    "unexpected errors. Is there a way to better handle this situation?\n",
    "\n",
    "We can raise the `FailedTrialError` to skip the retries. Whenever, this error is\n",
    "raised, the trial would not be retried. The retries will still run when other\n",
    "errors occur. An example is shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    # Define the 2 hyperparameters for the units in dense layers\n",
    "    units_1 = hp.Int(\"units_1\", 10, 40, step=10)\n",
    "    units_2 = hp.Int(\"units_2\", 10, 30, step=10)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=units_1, input_shape=(20,)),\n",
    "            layers.Dense(units=units_2),\n",
    "            layers.Dense(units=1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"mse\")\n",
    "\n",
    "    # Raise an error when the model is too large\n",
    "    num_params = model.count_params()\n",
    "    if num_params > 1200:\n",
    "        # When this error is raised, it skips the retries.\n",
    "        raise keras_tuner.errors.FailedTrialError(\n",
    "            f\"Model too large! It contains {num_params} params.\"\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    overwrite=True,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=8,\n",
    ")\n",
    "\n",
    "# Use random data to train the model.\n",
    "tuner.search(\n",
    "    x=np.random.rand(100, 20),\n",
    "    y=np.random.rand(100, 1),\n",
    "    validation_data=(\n",
    "        np.random.rand(100, 20),\n",
    "        np.random.rand(100, 1),\n",
    "    ),\n",
    "    epochs=10,\n",
    ")\n",
    "\n",
    "# Print the results.\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Terminate the search programmatically\n",
    "\n",
    "When there is a bug in the code we should terminate the search immediately and\n",
    "fix the bug. You can terminate the search programmatically when your defined\n",
    "conditions are met. Raising a `FatalError` (or its subclasses `FatalValueError`,\n",
    "`FatalTypeError`, or `FatalRuntimeError`) will terminate the search regardless\n",
    "of the `max_consecutive_failed_trials` argument.\n",
    "\n",
    "Following is an example to terminate the search when the model is too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    # Define the 2 hyperparameters for the units in dense layers\n",
    "    units_1 = hp.Int(\"units_1\", 10, 40, step=10)\n",
    "    units_2 = hp.Int(\"units_2\", 10, 30, step=10)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Dense(units=units_1, input_shape=(20,)),\n",
    "            layers.Dense(units=units_2),\n",
    "            layers.Dense(units=1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"mse\")\n",
    "\n",
    "    # Raise an error when the model is too large\n",
    "    num_params = model.count_params()\n",
    "    if num_params > 1200:\n",
    "        # When this error is raised, the search is terminated.\n",
    "        raise keras_tuner.errors.FatalError(\n",
    "            f\"Model too large! It contains {num_params} params.\"\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    overwrite=True,\n",
    "    max_retries_per_trial=3,\n",
    "    max_consecutive_failed_trials=8,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Use random data to train the model.\n",
    "    tuner.search(\n",
    "        x=np.random.rand(100, 20),\n",
    "        y=np.random.rand(100, 1),\n",
    "        validation_data=(\n",
    "            np.random.rand(100, 20),\n",
    "            np.random.rand(100, 1),\n",
    "        ),\n",
    "        epochs=10,\n",
    "    )\n",
    "except keras_tuner.errors.FatalError:\n",
    "    print(\"The search is terminated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "In this guide, you learn how to handle failed trials in KerasTuner:\n",
    "\n",
    "* Use `max_retries_per_trial` to specify the number of retries for a failed\n",
    "  trial.\n",
    "* Use `max_consecutive_failed_trials` to specify the maximum consecutive failed\n",
    "  trials to tolerate.\n",
    "* Raise `FailedTrialError` to directly mark a trial as failed and skip the\n",
    "  retries.\n",
    "* Raise `FatalError`, `FatalValueError`, `FatalTypeError`, `FatalRuntimeError`\n",
    "  to terminate the search immediately."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "failed_trials",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}