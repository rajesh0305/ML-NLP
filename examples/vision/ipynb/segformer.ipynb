{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Semantic segmentation with SegFormer and Hugging Face Transformers\n",
    "\n",
    "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
    "**Date created:** 2023/01/25<br>\n",
    "**Last modified:** 2023/01/29<br>\n",
    "**Description:** Fine-tuning a SegFormer model variant for semantic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we show how to fine-tune a SegFormer model variant to do\n",
    "semantic segmentation on a custom dataset. Semantic segmentation is the task of\n",
    "assigning a category to each and every pixel of an image. SegFormer was proposed in\n",
    "[SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203).\n",
    "SegFormer uses a hierarchical Transformer architecture (called \"Mix Transformer\") as\n",
    "its encoder and a lightweight decoder for segmentation. As a result, it yields\n",
    "state-of-the-art performance on semantic segmentation while being more efficient than\n",
    "existing models. For more details, check out the original paper.\n",
    "\n",
    "![segformer-arch](https://i.imgur.com/BsrVwYe.png)\n",
    "\n",
    "We leverage\n",
    "[Hugging Face Transformers](https://github.com/huggingface/transformers)\n",
    "to load a pretrained SegFormer checkpoint and fine-tune it on a custom dataset.\n",
    "\n",
    "**Note:** this example reuses code from the following sources:\n",
    "\n",
    "* [Official tutorial on segmentation from the TensorFlow team](https://www.tensorflow.org/tutorials/images/segmentation)\n",
    "* [Hugging Face Task guide on segmentation](https://huggingface.co/docs/transformers/main/en/tasks/semantic_segmentation)\n",
    "\n",
    "To run this example, we need to install the `transformers` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!pip install transformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "We use the [Oxford-IIIT Pets](https://www.robots.ox.ac.uk/~vgg/data/pets/) dataset for\n",
    "this example. We leverage `tensorflow_datasets` to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load(\"oxford_iiit_pet:3.*.*\", with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prepare the datasets\n",
    "\n",
    "For preparing the datasets for training and evaluation, we:\n",
    "\n",
    "* Normalize the images with the mean and standard deviation used during pre-training\n",
    "SegFormer.\n",
    "* Subtract 1 from the segmentation masks so that the pixel values start from 0.\n",
    "* Resize the images.\n",
    "* Transpose the images such that they are in `\"channels_first\"` format. This is to make\n",
    "them compatible with the SegFormer model from Hugging Face Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "image_size = 512\n",
    "mean = tf.constant([0.485, 0.456, 0.406])\n",
    "std = tf.constant([0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.image.convert_image_dtype(input_image, tf.float32)\n",
    "    input_image = (input_image - mean) / tf.maximum(std, backend.epsilon())\n",
    "    input_mask -= 1\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image(datapoint):\n",
    "    input_image = tf.image.resize(datapoint[\"image\"], (image_size, image_size))\n",
    "    input_mask = tf.image.resize(\n",
    "        datapoint[\"segmentation_mask\"],\n",
    "        (image_size, image_size),\n",
    "        method=\"bilinear\",\n",
    "    )\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    input_image = tf.transpose(input_image, (2, 0, 1))\n",
    "    return {\"pixel_values\": input_image, \"labels\": tf.squeeze(input_mask)}\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We now use the above utilities to prepare `tf.data.Dataset` objects including\n",
    "`prefetch()` for performance. Change the `batch_size` to match the size of the GPU memory\n",
    "on the GPU that you're using for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "auto = tf.data.AUTOTUNE\n",
    "batch_size = 4\n",
    "\n",
    "train_ds = (\n",
    "    dataset[\"train\"]\n",
    "    .cache()\n",
    "    .shuffle(batch_size * 10)\n",
    "    .map(load_image, num_parallel_calls=auto)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    ")\n",
    "test_ds = (\n",
    "    dataset[\"test\"]\n",
    "    .map(load_image, num_parallel_calls=auto)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(auto)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We can check the shapes of the input images and their segmentation maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(train_ds.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for samples in train_ds.take(2):\n",
    "    sample_image, sample_mask = samples[\"pixel_values\"][0], samples[\"labels\"][0]\n",
    "    sample_image = tf.transpose(sample_image, (1, 2, 0))\n",
    "    sample_mask = tf.expand_dims(sample_mask, -1)\n",
    "    display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load a pretrained SegFormer checkpoint\n",
    "\n",
    "We now load a pretrained SegFormer model variant from Hugging Face Transformers. The\n",
    "SegFormer model comes in different variants dubbed as **MiT-B0** to **MiT-B5**. You can\n",
    "find these checkpoints\n",
    "[here](https://huggingface.co/models?pipeline_tag=image-segmentation&sort=downloads&search=segformer).\n",
    "We load the smallest variant Mix-B0, which produces a good trade-off\n",
    "between inference efficiency and predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from transformers import TFSegformerForSemanticSegmentation\n",
    "\n",
    "model_checkpoint = \"nvidia/mit-b0\"\n",
    "id2label = {0: \"outer\", 1: \"inner\", 2: \"border\"}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "num_labels = len(id2label)\n",
    "model = TFSegformerForSemanticSegmentation.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The warning is telling us that we're throwing away some weights and newly initializing\n",
    "some others. Don't panic! This is absolutely normal. Since we're using a custom dataset\n",
    "which has a different set of semantic class labels than the pre-training dataset,\n",
    "[`TFSegformerForSemanticSegmentation`](https://huggingface.co/docs/transformers/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation)\n",
    "is initializing a new decoder head.\n",
    "\n",
    "We can now initialize an optimizer and compile the model with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "lr = 0.00006\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Notice that we are not using any loss function for compiling the model. This is because\n",
    "the forward pass of the model\n",
    "[implements](https://github.com/huggingface/transformers/blob/820c46a707ddd033975bc3b0549eea200e64c7da/src/transformers/models/segformer/modeling_tf_segformer.py#L873)\n",
    "the loss computation part when we provide labels alongside the input images. After\n",
    "computing the loss, the model returned a structured `dataclass` object which is\n",
    "then used to guide the training process.\n",
    "\n",
    "With the compiled model, we can proceed and call `fit()` on it to begin the fine-tuning\n",
    "process!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Prediction callback to monitor training progress\n",
    "\n",
    "It helps us to visualize some sample predictions when the model is being fine-tuned,\n",
    "thereby helping us to monitor the progress of the model. This callback is inspired from\n",
    "[this tutorial](https://www.tensorflow.org/tutorials/images/segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.math.argmax(pred_mask, axis=1)\n",
    "    pred_mask = tf.expand_dims(pred_mask, -1)\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for sample in dataset.take(num):\n",
    "            images, masks = sample[\"pixel_values\"], sample[\"labels\"]\n",
    "            masks = tf.expand_dims(masks, -1)\n",
    "            pred_masks = model.predict(images).logits\n",
    "            images = tf.transpose(images, (0, 2, 3, 1))\n",
    "            display([images[0], masks[0], create_mask(pred_masks)])\n",
    "    else:\n",
    "        display(\n",
    "            [\n",
    "                sample_image,\n",
    "                sample_mask,\n",
    "                create_mask(model.predict(tf.expand_dims(sample_image, 0))),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(self.dataset)\n",
    "        print(\"\\nSample Prediction after epoch {}\\n\".format(epoch + 1))\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Increase the number of epochs if the results are not of expected quality.\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[DisplayCallback(test_ds)],\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Inference\n",
    "\n",
    "We perform inference on a few samples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "show_predictions(test_ds, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example, we learned how to fine-tune a SegFormer model variant on a custom\n",
    "dataset for semantic segmentation. In the interest of brevity, the example\n",
    "was kept short. However, there are a couple of things, you can further try out:\n",
    "\n",
    "* Incorporate data augmentation to potentially improve the results.\n",
    "* Use a larger SegFormer model checkpoint to see how the results are affected.\n",
    "* Push the fine-tuned model to the Hugging Face for sharing with the community easily.\n",
    "You can do so just by doing `model.push_to_hub(\"your-username/your-awesome-model\")`.\n",
    "And then you can load the model by doing\n",
    "`TFSegformerForSemanticSegmentation.from_pretrained(\"your-username/your-awesome-model\"`).\n",
    "[Here](https://github.com/huggingface/notebooks/blob/main/examples/semantic_segmentation-tf.ipynb)\n",
    "is an end-to-end example if you're looking for a reference.\n",
    "* If you'd rather push the model checkpoints to the Hub as the model is being\n",
    "fine-tuned you can instead use the `PushToHubCallback` Keras callback.\n",
    "[Here](https://gist.github.com/sayakpaul/f474ffb01f0cdcc8ba239357965c3bca) is an example.\n",
    "[Here](https://huggingface.co/sayakpaul/mit-b0-finetuned-pets) is an example of a model\n",
    "repository that was created using this callback."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "segformer",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}